DE-DUPLICATION ESTIMATOR

This project is the pre-migration aid for compressed/de-duplicated
filesystems. It helps to know the possible savings having de-duplication
and/or compression enabled on the filesystem before actually committing
to this decision.

The tools walks the real filesystem and emulates per-block compression
and de-duplication, printing out the compressibility info. This can
also be used as the information entropy estimate.

Quick-start:
--------------------------------------------------------------------

Build for source:
 $ mvn clean install
 $ java -jar target/dedup.jar <path>

Binary builds are available here:
 https://builds.shipilev.net/dedup-estimator/

Sample output:
--------------------------------------------------------------------

/home/shade/trunks/, using 4096-byte blocks
Running at 1296.65 MB/sec (4558.53 GB/hour), 0/1000000 files, 55995/55995 MB, ETA: 0s
COMPRESS:       1.250x increase, 55,995 MB --(block-compress)--> 44,797 MB
DEDUP:          1.311x increase, 55,995 MB ------(dedup)-------> 42,702 MB
DEDUP+COMPRESS: 1.564x increase, 55,995 MB ------(dedup)-------> 42,702 MB --(block-compress)--> 35,813 MB

Settings to play with:
--------------------------------------------------------------------

 -Dthreads = # (default is #numCPU)
    Number of processing threads.

 -DblockSize = # (default is 4096)
    Target filesystem block size.

 -Dhash = # (default is "SHA-256")
    Hash to use for deduplication

 -Dstorage = # (default is "inmemory")
    Hash storage implementation. Bundled implementations:
      - inmemory: uses ConcurrentHashMap to store on heap
      - berkeley: uses on-disk BerkeleyDB
      - h2:       uses on-disk H2
      - derby:    uses on-disk Apache Derby

Caveats:
--------------------------------------------------------------------

* Default mode uses in-memory hash storage, which can OOM on large
  enough datasets. Consider using off-heap storage for large FSes.
  The rule of thumb: 1G of heap space can take up 2M+ hashes,
  which translates to ~10G total FS size with 4K blocks.
